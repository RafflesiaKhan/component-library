{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "binding-delta",
   "metadata": {
    "papermill": {
     "duration": 0.016304,
     "end_time": "2021-03-22T20:29:23.476444",
     "exception": false,
     "start_time": "2021-03-22T20:29:23.460140",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# anomaly_score_unsupervised"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb97e294-9399-4d96-a95c-8ad7e29a2872",
   "metadata": {},
   "source": [
    "Send arbitrary time-series data to the component and train an unsupervised LSTM-Autoencoder model. The moment unseen patters occur the anomaly score rises.\n",
    "\n",
    "Future work:\n",
    "\n",
    "- reset / rollback model (for regular flushing or after a real anomaly (true positive) occurred)\n",
    "- add check-pointing for service persistence and rollback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "884bff3a-dc51-4c8b-a98f-1d0a8ac1de94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "#os.environ['create_image']='True'\n",
    "#os.environ['repository']='romeokienzler'\n",
    "#os.environ['version']='0.1'\n",
    "#\n",
    "os.environ['install_requirements']='True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f19a1a1-9cf2-4cb6-a0d0-859c9de3a525",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow==2.9.1 in /opt/conda/lib/python3.9/site-packages (2.9.1)\n",
      "Collecting numpy==1.23.2\n",
      "  Using cached numpy-1.23.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
      "Collecting scikit-learn==1.1.2\n",
      "  Using cached scikit_learn-1.1.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30.8 MB)\n",
      "Requirement already satisfied: pandas==1.4.3 in /opt/conda/lib/python3.9/site-packages (1.4.3)\n",
      "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in /opt/conda/lib/python3.9/site-packages (from tensorflow==2.9.1) (2.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.9/site-packages (from tensorflow==2.9.1) (4.3.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.9/site-packages (from tensorflow==2.9.1) (63.2.0)\n",
      "Requirement already satisfied: tensorboard<2.10,>=2.9 in /opt/conda/lib/python3.9/site-packages (from tensorflow==2.9.1) (2.9.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.9/site-packages (from tensorflow==2.9.1) (1.47.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /opt/conda/lib/python3.9/site-packages (from tensorflow==2.9.1) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.9/site-packages (from tensorflow==2.9.1) (0.26.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in /opt/conda/lib/python3.9/site-packages (from tensorflow==2.9.1) (1.1.2)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.9/site-packages (from tensorflow==2.9.1) (14.0.6)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /opt/conda/lib/python3.9/site-packages (from tensorflow==2.9.1) (0.4.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.9/site-packages (from tensorflow==2.9.1) (3.3.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.9/site-packages (from tensorflow==2.9.1) (1.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.9/site-packages (from tensorflow==2.9.1) (1.6.3)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.9/site-packages (from tensorflow==2.9.1) (3.7.0)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.9/site-packages (from tensorflow==2.9.1) (21.2)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /opt/conda/lib/python3.9/site-packages (from tensorflow==2.9.1) (3.19.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.9/site-packages (from tensorflow==2.9.1) (0.2.0)\n",
      "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in /opt/conda/lib/python3.9/site-packages (from tensorflow==2.9.1) (2.9.0)\n",
      "Requirement already satisfied: flatbuffers<2,>=1.12 in /opt/conda/lib/python3.9/site-packages (from tensorflow==2.9.1) (1.12)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.9/site-packages (from tensorflow==2.9.1) (1.2.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.9/site-packages (from tensorflow==2.9.1) (1.16.0)\n",
      "Collecting scipy>=1.3.2\n",
      "  Downloading scipy-1.9.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (43.9 MB)\n",
      "     |████████████████████████████████| 43.9 MB 72.3 MB/s            2/s eta 0:00:01\n",
      "\u001b[?25hCollecting joblib>=1.0.0\n",
      "  Downloading joblib-1.1.0-py2.py3-none-any.whl (306 kB)\n",
      "     |████████████████████████████████| 306 kB 54.1 MB/s            \n",
      "\u001b[?25hCollecting threadpoolctl>=2.0.0\n",
      "  Downloading threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.9/site-packages (from pandas==1.4.3) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.9/site-packages (from pandas==1.4.3) (2021.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.9/site-packages (from astunparse>=1.6.0->tensorflow==2.9.1) (0.37.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.9/site-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.1) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /opt/conda/lib/python3.9/site-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.1) (0.6.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.9/site-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.1) (0.4.6)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.9/site-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.1) (2.2.2)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/lib/python3.9/site-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.1) (1.8.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.9/site-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.1) (1.35.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.9/site-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.1) (2.26.0)\n",
      "Requirement already satisfied: pyparsing<3,>=2.0.2 in /opt/conda/lib/python3.9/site-packages (from packaging->tensorflow==2.9.1) (2.4.7)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9.1) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9.1) (4.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9.1) (4.2.4)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.9/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow==2.9.1) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /opt/conda/lib/python3.9/site-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow==2.9.1) (4.8.1)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow==2.9.1) (2.0.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow==2.9.1) (3.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow==2.9.1) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow==2.9.1) (1.26.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.9/site-packages (from werkzeug>=1.0.1->tensorboard<2.10,>=2.9->tensorflow==2.9.1) (2.1.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.9/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow==2.9.1) (3.6.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9.1) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.9/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow==2.9.1) (3.1.1)\n",
      "Installing collected packages: numpy, threadpoolctl, scipy, joblib, scikit-learn\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.23.1\n",
      "    Uninstalling numpy-1.23.1:\n",
      "      Successfully uninstalled numpy-1.23.1\n",
      "Successfully installed joblib-1.1.0 numpy-1.23.2 scikit-learn-1.1.2 scipy-1.9.0 threadpoolctl-3.1.0\n"
     ]
    }
   ],
   "source": [
    "if bool(os.environ.get('create_image',False)):\n",
    "    docker_file=\"\"\"\n",
    "    FROM registry.access.redhat.com/ubi8/python-39\n",
    "    RUN pip install ipython nbformat numpy ibm-cos-sdk-core ibm-cos-sdk ibm-watson-machine-learning ibm-watson-studio-pipelines ibmcloudsql pyyaml\n",
    "    ADD ibm-sql-query-cpd.py .\n",
    "    ADD start.sh .\n",
    "\n",
    "    \"\"\"\n",
    "    with open(\"Dockerfile\", \"w\") as text_file:\n",
    "        text_file.write(docker_file)\n",
    "\n",
    "    start_file=\"\"\"\n",
    "    #!/bin/bash\n",
    "    echo \"Parameter 1: $1\"\n",
    "    echo \"Parameter 2: $2\"\n",
    "    echo \"Parameter 3: $3\"\n",
    "    echo \"Parameter 4: $4\"\n",
    "    echo \"Parameter 5: $5\"\n",
    "    echo \"Parameter 6: $6\"\n",
    "    echo \"Parameter 7: $7\"\n",
    "    echo \"Parameter 8: $8\"\n",
    "    echo \"Parameter 9: $9\"\n",
    "    echo \"Parameter 10: ${10}\"\n",
    "    echo \"Parameter 11: ${11}\"\n",
    "    echo \"Parameter 12: ${12}\"\n",
    "    echo \"Parameter 13: ${13}\"\n",
    "    echo \"Parameter 14: ${14}\"\n",
    "    echo \"Parameter 15: ${15}\"\n",
    "    echo \"Parameter 16: ${16}\"\n",
    "    echo \"Parameter 17: ${17}\"\n",
    "    echo \"Parameter 18: ${18}\"\n",
    "    echo \"Parameter 19: ${19}\"\n",
    "    echo \"Parameter 20: ${20}\"\n",
    "    python /opt/app-root/src/ibm-sql-query-cpd.py \"$1$2\" \"$3$4\" \"$5$6\" \"$7$8\" \"$9${10}\" \"${11}${12}\" \"${13}${14}\" \"${15}${16}\" \"${17}${18}\" \"${19}${20}\"\n",
    "    \"\"\"\n",
    "    with open(\"start.sh\", \"w\") as text_file:\n",
    "        text_file.write(start_file)\n",
    "\n",
    "    !chmod 755 start.sh\n",
    "    !jupyter nbconvert --to script ibm-sql-query-cpd.ipynb    \n",
    "    !docker build -t ibm_sql_query_cpd:`echo $version` .\n",
    "    !docker tag ibm_sql_query_cpd:`echo $version` `echo $repository`/ibm_sql_query_cpd:`echo $version`\n",
    "    !docker push `echo $repository`/ibm_sql_query_cpd:`echo $version`\n",
    "    !rm Dockerfile\n",
    "    !rm ibm-sql-query-cpd.py\n",
    "    !rm start.sh\n",
    "elif bool(os.environ.get('install_requirements',False)):\n",
    "    !pip install tensorflow==2.9.1 numpy==1.23.2 scikit-learn==1.1.2  pandas==1.4.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4e63f153-5524-4c3a-8b55-2afb01f2750b",
   "metadata": {
    "papermill": {
     "duration": 0.164002,
     "end_time": "2021-03-22T20:29:25.951504",
     "exception": false,
     "start_time": "2021-03-22T20:29:25.787502",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import concatenate\n",
    "from matplotlib import pyplot\n",
    "from pandas import read_csv\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "import sklearn\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Activation\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abstract-cambridge",
   "metadata": {
    "papermill": {
     "duration": 0.012801,
     "end_time": "2021-03-22T20:29:25.972462",
     "exception": false,
     "start_time": "2021-03-22T20:29:25.959661",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# COS URL where the results of the SQL job are to be stored\n",
    "target_dir_path = os.environ.get('target_dir_path')\n",
    "\n",
    "# Asset name to register for the results written by the SQL job\n",
    "target_asset_name = os.environ.get('target_asset_name')\n",
    "\n",
    "# sql statement to execute\n",
    "sql = os.environ.get('sql')\n",
    "\n",
    "# (unique) Custom Resource Name (CRN) of IBM SQL Query Service\n",
    "data_engine_crn = os.environ.get('data_engine_crn')\n",
    "\n",
    "# default: CSV - (will be generated into according STORED AS … clause in the INTO clause)\n",
    "format = os.environ.get('format' , 'CSV')\n",
    "\n",
    "# optional, list of columns to use for partitioning the results of the SQL job, will be generated into according PARTITIONED BY (<columns>) clause in the INTO clause)\n",
    "partition_columns = os.environ.get('partition_columns','')\n",
    "\n",
    "# optional, number of objects to store the results of the SQL job in, will be generated into according PARTITIONED INTO <num> OBJECTS clause in INTO clause\n",
    "number_of_objects = int(os.environ.get('number_of_objects', 0))\n",
    "\n",
    "# optional, number of rows to be stored in each result object of the SQL job, will be generated into according PARTITIONED EVERY <num> ROWS clause in INTO clause\n",
    "rows_per_object = int(os.environ.get('rows_per_object', 0))\n",
    "\n",
    "# default: False, only valid when none of the above partitioning option is specified, produces exactly one object with name specified in target_dir_path, twill be generated into sqlClient.rename_exact_result(jobid) after SQL has run.\n",
    "exact_name = os.environ.get('exact_name', 'False')\n",
    "\n",
    "# default: False - will be generated into JOBPREFIX NONE in the INTO clause. Will cause results of previous runs with same output_uri to be overwritten, because no unique sub folder will be created for the result)\n",
    "no_jobid_folder = os.environ.get('no_jobid_folder', 'False')\n",
    "\n",
    "# default: output.txt - output file name containing the CPD path of the resulting asset\n",
    "data_asset = os.environ.get('data_asset','output.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f9b39f-2c8c-4ab5-b4f5-513357bf20ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "for element in sys.argv:\n",
    "    logging.warning('argv raw ' +  element)\n",
    "\n",
    "parameters = list(\n",
    "    map(lambda s: re.sub('$', '\"', s),\n",
    "        map(\n",
    "            lambda s: s.replace('=', '=\"'),\n",
    "            filter(\n",
    "                lambda s: s.find('=') > -1 and bool(re.match(r'[A-Za-z0-9_]*=[.\\/A-Za-z0-9]*', s)),\n",
    "                sys.argv\n",
    "            )\n",
    "    )))\n",
    "\n",
    "\n",
    "for parameter in parameters:\n",
    "    exec(parameter)\n",
    "    logging.warning('Parameter: ' + parameter)\n",
    "\n",
    "exact_name = ast.literal_eval(exact_name.capitalize())\n",
    "no_jobid_folder = ast.literal_eval(no_jobid_folder.capitalize())\n",
    "number_of_objects = number_of_objects if type(number_of_objects)==int else int(number_of_objects) if len(number_of_objects)>0 else 0\n",
    "rows_per_object = rows_per_object if type(rows_per_object)==int else int(rows_per_object) if len(rows_per_object)>0 else 0\n",
    "\n",
    "\n",
    "for parameter in parameters:\n",
    "    exec(\"logging.warning('final parameter: ' + str({}))\".format(parameter.split('=')[0]))\n",
    "    exec(\"logging.warning('final parameter type: ' + str(type({})))\".format(parameter.split('=')[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "547ec6d4-85e9-4e6c-ae5a-0c8aae8ef9d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove 'watsoniotp.*': No such file or directory\n",
      "--2022-08-19 07:28:12--  https://raw.githubusercontent.com/romeokienzler/developerWorks/master/lorenzattractor/watsoniotp.healthy.phase_aligned.pickle\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.110.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 194639 (190K) [text/plain]\n",
      "Saving to: ‘watsoniotp.healthy.phase_aligned.pickle’\n",
      "\n",
      "watsoniotp.healthy. 100%[===================>] 190.08K  --.-KB/s    in 0.005s  \n",
      "\n",
      "2022-08-19 07:28:12 (37.4 MB/s) - ‘watsoniotp.healthy.phase_aligned.pickle’ saved [194639/194639]\n",
      "\n",
      "--2022-08-19 07:28:13--  https://raw.githubusercontent.com/romeokienzler/developerWorks/master/lorenzattractor/watsoniotp.broken.phase_aligned.pickle\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.109.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 185401 (181K) [text/plain]\n",
      "Saving to: ‘watsoniotp.broken.phase_aligned.pickle’\n",
      "\n",
      "watsoniotp.broken.p 100%[===================>] 181.06K  --.-KB/s    in 0.002s  \n",
      "\n",
      "2022-08-19 07:28:13 (72.4 MB/s) - ‘watsoniotp.broken.phase_aligned.pickle’ saved [185401/185401]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!rm watsoniotp.*\n",
    "!wget https://raw.githubusercontent.com/romeokienzler/developerWorks/master/lorenzattractor/watsoniotp.healthy.phase_aligned.pickle\n",
    "!wget https://raw.githubusercontent.com/romeokienzler/developerWorks/master/lorenzattractor/watsoniotp.broken.phase_aligned.pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "38e8d12c-aa8a-42c6-9720-6b141485f919",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "a bytes-like object is required, not 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_365879/3917896644.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata_healthy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'watsoniotp.healthy.phase_aligned.pickle'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'iso-8859-1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdata_broken\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'watsoniotp.broken.phase_aligned.pickle'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'iso-8859-1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: a bytes-like object is required, not 'str'"
     ]
    }
   ],
   "source": [
    "data_healthy = pickle.load(open('watsoniotp.healthy.phase_aligned.pickle', encoding='iso-8859-1'))\n",
    "data_broken = pickle.load(open('watsoniotp.broken.phase_aligned.pickle', encoding='iso-8859-1'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ad728c-70aa-41b6-9885-40d3b32708f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_healthy = data_healthy.reshape(3000,3)\n",
    "data_broken = data_broken.reshape(3000,3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8d85be76-c42f-4967-9525-5c273ca4efa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaleData(data):\n",
    "    # normalize features\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    return scaler.fit_transform(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "57b3c3ad-435c-47af-84a1-7f5949aa9f21",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_healthy_scaled' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_365879/1182529457.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdata_healthy_scaled_reshaped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_healthy_scaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;31m#reshape to (300,10,3)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mdata_healthy_scaled_reshaped\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mtimesteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtimesteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data_healthy_scaled' is not defined"
     ]
    }
   ],
   "source": [
    "timesteps = 10\n",
    "dim = 3\n",
    "samples = 3000\n",
    "data_healthy_scaled_reshaped = data_healthy_scaled\n",
    "#reshape to (300,10,3)\n",
    "data_healthy_scaled_reshaped.shape = (samples/timesteps,timesteps,dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75983ac5-9abd-4d01-b864-8015b18e5e83",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 470.538548,
   "end_time": "2021-03-22T20:37:13.369954",
   "environment_variables": {},
   "exception": null,
   "input_path": "/home/jovyan/work/examples/pipelines/pairs/component-library/transform/spark-csv-to-parquet.ipynb",
   "output_path": "/home/jovyan/work/examples/pipelines/pairs/component-library/transform/spark-csv-to-parquet.ipynb",
   "parameters": {},
   "start_time": "2021-03-22T20:29:22.831406",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
