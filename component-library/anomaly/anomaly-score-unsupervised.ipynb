{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "binding-delta",
   "metadata": {
    "papermill": {
     "duration": 0.016304,
     "end_time": "2021-03-22T20:29:23.476444",
     "exception": false,
     "start_time": "2021-03-22T20:29:23.460140",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# anomaly_score_unsupervised"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb97e294-9399-4d96-a95c-8ad7e29a2872",
   "metadata": {},
   "source": [
    "Send arbitrary time-series data to the component and train an unsupervised LSTM-Autoencoder model. The moment unseen patters occur the anomaly score rises.\n",
    "\n",
    "Future work:\n",
    "\n",
    "- reset / rollback model (for regular flushing or after a real anomaly (true positive) occurred)\n",
    "- add check-pointing for service persistence and rollback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "884bff3a-dc51-4c8b-a98f-1d0a8ac1de94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "#os.environ['create_image']='True'\n",
    "#os.environ['repository']='romeokienzler'\n",
    "#os.environ['version']='0.1'\n",
    "#\n",
    "os.environ['install_requirements']='True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f19a1a1-9cf2-4cb6-a0d0-859c9de3a525",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow==2.9.1 in /opt/conda/lib/python3.9/site-packages (2.9.1)\n",
      "Collecting numpy==1.23.2\n",
      "  Using cached numpy-1.23.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
      "Collecting scikit-learn==1.1.2\n",
      "  Using cached scikit_learn-1.1.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30.8 MB)\n",
      "Requirement already satisfied: pandas==1.4.3 in /opt/conda/lib/python3.9/site-packages (1.4.3)\n",
      "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in /opt/conda/lib/python3.9/site-packages (from tensorflow==2.9.1) (2.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.9/site-packages (from tensorflow==2.9.1) (4.3.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.9/site-packages (from tensorflow==2.9.1) (63.2.0)\n",
      "Requirement already satisfied: tensorboard<2.10,>=2.9 in /opt/conda/lib/python3.9/site-packages (from tensorflow==2.9.1) (2.9.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.9/site-packages (from tensorflow==2.9.1) (1.47.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /opt/conda/lib/python3.9/site-packages (from tensorflow==2.9.1) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.9/site-packages (from tensorflow==2.9.1) (0.26.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in /opt/conda/lib/python3.9/site-packages (from tensorflow==2.9.1) (1.1.2)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.9/site-packages (from tensorflow==2.9.1) (14.0.6)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /opt/conda/lib/python3.9/site-packages (from tensorflow==2.9.1) (0.4.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.9/site-packages (from tensorflow==2.9.1) (3.3.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.9/site-packages (from tensorflow==2.9.1) (1.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.9/site-packages (from tensorflow==2.9.1) (1.6.3)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.9/site-packages (from tensorflow==2.9.1) (3.7.0)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.9/site-packages (from tensorflow==2.9.1) (21.2)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /opt/conda/lib/python3.9/site-packages (from tensorflow==2.9.1) (3.19.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.9/site-packages (from tensorflow==2.9.1) (0.2.0)\n",
      "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in /opt/conda/lib/python3.9/site-packages (from tensorflow==2.9.1) (2.9.0)\n",
      "Requirement already satisfied: flatbuffers<2,>=1.12 in /opt/conda/lib/python3.9/site-packages (from tensorflow==2.9.1) (1.12)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.9/site-packages (from tensorflow==2.9.1) (1.2.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.9/site-packages (from tensorflow==2.9.1) (1.16.0)\n",
      "Collecting scipy>=1.3.2\n",
      "  Downloading scipy-1.9.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (43.9 MB)\n",
      "     |████████████████████████████████| 43.9 MB 72.3 MB/s            2/s eta 0:00:01\n",
      "\u001b[?25hCollecting joblib>=1.0.0\n",
      "  Downloading joblib-1.1.0-py2.py3-none-any.whl (306 kB)\n",
      "     |████████████████████████████████| 306 kB 54.1 MB/s            \n",
      "\u001b[?25hCollecting threadpoolctl>=2.0.0\n",
      "  Downloading threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.9/site-packages (from pandas==1.4.3) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.9/site-packages (from pandas==1.4.3) (2021.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.9/site-packages (from astunparse>=1.6.0->tensorflow==2.9.1) (0.37.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.9/site-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.1) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /opt/conda/lib/python3.9/site-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.1) (0.6.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.9/site-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.1) (0.4.6)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.9/site-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.1) (2.2.2)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/lib/python3.9/site-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.1) (1.8.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.9/site-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.1) (1.35.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.9/site-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.1) (2.26.0)\n",
      "Requirement already satisfied: pyparsing<3,>=2.0.2 in /opt/conda/lib/python3.9/site-packages (from packaging->tensorflow==2.9.1) (2.4.7)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9.1) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9.1) (4.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9.1) (4.2.4)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.9/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow==2.9.1) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /opt/conda/lib/python3.9/site-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow==2.9.1) (4.8.1)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow==2.9.1) (2.0.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow==2.9.1) (3.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow==2.9.1) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow==2.9.1) (1.26.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.9/site-packages (from werkzeug>=1.0.1->tensorboard<2.10,>=2.9->tensorflow==2.9.1) (2.1.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.9/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow==2.9.1) (3.6.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9.1) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.9/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow==2.9.1) (3.1.1)\n",
      "Installing collected packages: numpy, threadpoolctl, scipy, joblib, scikit-learn\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.23.1\n",
      "    Uninstalling numpy-1.23.1:\n",
      "      Successfully uninstalled numpy-1.23.1\n",
      "Successfully installed joblib-1.1.0 numpy-1.23.2 scikit-learn-1.1.2 scipy-1.9.0 threadpoolctl-3.1.0\n"
     ]
    }
   ],
   "source": [
    "if bool(os.environ.get('create_image',False)):\n",
    "    docker_file=\"\"\"\n",
    "    FROM registry.access.redhat.com/ubi8/python-39\n",
    "    RUN pip install ipython nbformat numpy ibm-cos-sdk-core ibm-cos-sdk ibm-watson-machine-learning ibm-watson-studio-pipelines ibmcloudsql pyyaml\n",
    "    ADD ibm-sql-query-cpd.py .\n",
    "    ADD start.sh .\n",
    "\n",
    "    \"\"\"\n",
    "    with open(\"Dockerfile\", \"w\") as text_file:\n",
    "        text_file.write(docker_file)\n",
    "\n",
    "    start_file=\"\"\"\n",
    "    #!/bin/bash\n",
    "    echo \"Parameter 1: $1\"\n",
    "    echo \"Parameter 2: $2\"\n",
    "    echo \"Parameter 3: $3\"\n",
    "    echo \"Parameter 4: $4\"\n",
    "    echo \"Parameter 5: $5\"\n",
    "    echo \"Parameter 6: $6\"\n",
    "    echo \"Parameter 7: $7\"\n",
    "    echo \"Parameter 8: $8\"\n",
    "    echo \"Parameter 9: $9\"\n",
    "    echo \"Parameter 10: ${10}\"\n",
    "    echo \"Parameter 11: ${11}\"\n",
    "    echo \"Parameter 12: ${12}\"\n",
    "    echo \"Parameter 13: ${13}\"\n",
    "    echo \"Parameter 14: ${14}\"\n",
    "    echo \"Parameter 15: ${15}\"\n",
    "    echo \"Parameter 16: ${16}\"\n",
    "    echo \"Parameter 17: ${17}\"\n",
    "    echo \"Parameter 18: ${18}\"\n",
    "    echo \"Parameter 19: ${19}\"\n",
    "    echo \"Parameter 20: ${20}\"\n",
    "    python /opt/app-root/src/ibm-sql-query-cpd.py \"$1$2\" \"$3$4\" \"$5$6\" \"$7$8\" \"$9${10}\" \"${11}${12}\" \"${13}${14}\" \"${15}${16}\" \"${17}${18}\" \"${19}${20}\"\n",
    "    \"\"\"\n",
    "    with open(\"start.sh\", \"w\") as text_file:\n",
    "        text_file.write(start_file)\n",
    "\n",
    "    !chmod 755 start.sh\n",
    "    !jupyter nbconvert --to script ibm-sql-query-cpd.ipynb    \n",
    "    !docker build -t ibm_sql_query_cpd:`echo $version` .\n",
    "    !docker tag ibm_sql_query_cpd:`echo $version` `echo $repository`/ibm_sql_query_cpd:`echo $version`\n",
    "    !docker push `echo $repository`/ibm_sql_query_cpd:`echo $version`\n",
    "    !rm Dockerfile\n",
    "    !rm ibm-sql-query-cpd.py\n",
    "    !rm start.sh\n",
    "elif bool(os.environ.get('install_requirements',False)):\n",
    "    !pip install tensorflow==2.9.1 numpy==1.23.2 scikit-learn==1.1.2  pandas==1.4.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4e63f153-5524-4c3a-8b55-2afb01f2750b",
   "metadata": {
    "papermill": {
     "duration": 0.164002,
     "end_time": "2021-03-22T20:29:25.951504",
     "exception": false,
     "start_time": "2021-03-22T20:29:25.787502",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import concatenate\n",
    "from matplotlib import pyplot\n",
    "from pandas import read_csv\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "import sklearn\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Activation\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abstract-cambridge",
   "metadata": {
    "papermill": {
     "duration": 0.012801,
     "end_time": "2021-03-22T20:29:25.972462",
     "exception": false,
     "start_time": "2021-03-22T20:29:25.959661",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# COS URL where the results of the SQL job are to be stored\n",
    "target_dir_path = os.environ.get('target_dir_path')\n",
    "\n",
    "# Asset name to register for the results written by the SQL job\n",
    "target_asset_name = os.environ.get('target_asset_name')\n",
    "\n",
    "# sql statement to execute\n",
    "sql = os.environ.get('sql')\n",
    "\n",
    "# (unique) Custom Resource Name (CRN) of IBM SQL Query Service\n",
    "data_engine_crn = os.environ.get('data_engine_crn')\n",
    "\n",
    "# default: CSV - (will be generated into according STORED AS … clause in the INTO clause)\n",
    "format = os.environ.get('format' , 'CSV')\n",
    "\n",
    "# optional, list of columns to use for partitioning the results of the SQL job, will be generated into according PARTITIONED BY (<columns>) clause in the INTO clause)\n",
    "partition_columns = os.environ.get('partition_columns','')\n",
    "\n",
    "# optional, number of objects to store the results of the SQL job in, will be generated into according PARTITIONED INTO <num> OBJECTS clause in INTO clause\n",
    "number_of_objects = int(os.environ.get('number_of_objects', 0))\n",
    "\n",
    "# optional, number of rows to be stored in each result object of the SQL job, will be generated into according PARTITIONED EVERY <num> ROWS clause in INTO clause\n",
    "rows_per_object = int(os.environ.get('rows_per_object', 0))\n",
    "\n",
    "# default: False, only valid when none of the above partitioning option is specified, produces exactly one object with name specified in target_dir_path, twill be generated into sqlClient.rename_exact_result(jobid) after SQL has run.\n",
    "exact_name = os.environ.get('exact_name', 'False')\n",
    "\n",
    "# default: False - will be generated into JOBPREFIX NONE in the INTO clause. Will cause results of previous runs with same output_uri to be overwritten, because no unique sub folder will be created for the result)\n",
    "no_jobid_folder = os.environ.get('no_jobid_folder', 'False')\n",
    "\n",
    "# default: output.txt - output file name containing the CPD path of the resulting asset\n",
    "data_asset = os.environ.get('data_asset','output.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f9b39f-2c8c-4ab5-b4f5-513357bf20ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "for element in sys.argv:\n",
    "    logging.warning('argv raw ' +  element)\n",
    "\n",
    "parameters = list(\n",
    "    map(lambda s: re.sub('$', '\"', s),\n",
    "        map(\n",
    "            lambda s: s.replace('=', '=\"'),\n",
    "            filter(\n",
    "                lambda s: s.find('=') > -1 and bool(re.match(r'[A-Za-z0-9_]*=[.\\/A-Za-z0-9]*', s)),\n",
    "                sys.argv\n",
    "            )\n",
    "    )))\n",
    "\n",
    "\n",
    "for parameter in parameters:\n",
    "    exec(parameter)\n",
    "    logging.warning('Parameter: ' + parameter)\n",
    "\n",
    "exact_name = ast.literal_eval(exact_name.capitalize())\n",
    "no_jobid_folder = ast.literal_eval(no_jobid_folder.capitalize())\n",
    "number_of_objects = number_of_objects if type(number_of_objects)==int else int(number_of_objects) if len(number_of_objects)>0 else 0\n",
    "rows_per_object = rows_per_object if type(rows_per_object)==int else int(rows_per_object) if len(rows_per_object)>0 else 0\n",
    "\n",
    "\n",
    "for parameter in parameters:\n",
    "    exec(\"logging.warning('final parameter: ' + str({}))\".format(parameter.split('=')[0]))\n",
    "    exec(\"logging.warning('final parameter type: ' + str(type({})))\".format(parameter.split('=')[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "547ec6d4-85e9-4e6c-ae5a-0c8aae8ef9d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove 'watsoniotp.*': No such file or directory\n",
      "--2022-08-19 07:28:12--  https://raw.githubusercontent.com/romeokienzler/developerWorks/master/lorenzattractor/watsoniotp.healthy.phase_aligned.pickle\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.110.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 194639 (190K) [text/plain]\n",
      "Saving to: ‘watsoniotp.healthy.phase_aligned.pickle’\n",
      "\n",
      "watsoniotp.healthy. 100%[===================>] 190.08K  --.-KB/s    in 0.005s  \n",
      "\n",
      "2022-08-19 07:28:12 (37.4 MB/s) - ‘watsoniotp.healthy.phase_aligned.pickle’ saved [194639/194639]\n",
      "\n",
      "--2022-08-19 07:28:13--  https://raw.githubusercontent.com/romeokienzler/developerWorks/master/lorenzattractor/watsoniotp.broken.phase_aligned.pickle\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.109.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 185401 (181K) [text/plain]\n",
      "Saving to: ‘watsoniotp.broken.phase_aligned.pickle’\n",
      "\n",
      "watsoniotp.broken.p 100%[===================>] 181.06K  --.-KB/s    in 0.002s  \n",
      "\n",
      "2022-08-19 07:28:13 (72.4 MB/s) - ‘watsoniotp.broken.phase_aligned.pickle’ saved [185401/185401]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!rm watsoniotp.*\n",
    "!wget https://raw.githubusercontent.com/romeokienzler/developerWorks/master/lorenzattractor/watsoniotp.healthy.phase_aligned.pickle\n",
    "!wget https://raw.githubusercontent.com/romeokienzler/developerWorks/master/lorenzattractor/watsoniotp.broken.phase_aligned.pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "77a93042-b9fc-417c-9eea-7b2715219616",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('watsoniotp.healthy.phase_aligned.pickle','rb') as file_object:\n",
    "    raw_data = file_object.read()\n",
    "    data_healthy = pickle.loads(raw_data, encoding='latin1')\n",
    "\n",
    "with open('watsoniotp.broken.phase_aligned.pickle','rb') as file_object:\n",
    "    raw_data = file_object.read()\n",
    "    data_broken = pickle.loads(raw_data, encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "42ad728c-70aa-41b6-9885-40d3b32708f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_healthy = data_healthy.reshape(3000,3)\n",
    "data_broken = data_broken.reshape(3000,3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8d85be76-c42f-4967-9525-5c273ca4efa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaleData(data):\n",
    "    # normalize features\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    return scaler.fit_transform(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0315b9fc-14bb-4e14-ac77-08695ef12059",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_healthy_scaled = scaleData(data_healthy)\n",
    "data_broken_scaled = scaleData(data_broken)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "57b3c3ad-435c-47af-84a1-7f5949aa9f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "timesteps = 10\n",
    "dim = 3\n",
    "samples = 3000\n",
    "data_healthy_scaled_reshaped = data_healthy_scaled\n",
    "#reshape to (300,10,3)\n",
    "data_healthy_scaled_reshaped.shape = (int(samples/timesteps),timesteps,dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "75983ac5-9abd-4d01-b864-8015b18e5e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []\n",
    "\n",
    "def handleLoss(loss):\n",
    "        global losses\n",
    "        losses+=[loss]\n",
    "        print(loss)\n",
    "\n",
    "class LossHistory(Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.losses = []\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        self.losses.append(logs.get('loss'))\n",
    "        handleLoss(logs.get('loss'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7da08143-9d23-4992-8069-c69b45914142",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-19 07:48:51.611702: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-08-19 07:48:51.611823: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-08-19 07:48:51.611862: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (elyra): /proc/driver/nvidia/version does not exist\n",
      "2022-08-19 07:48:51.616415: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# design network\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(50,input_shape=(timesteps,dim),return_sequences=True))\n",
    "model.add(LSTM(50,input_shape=(timesteps,dim),return_sequences=True))\n",
    "model.add(LSTM(50,input_shape=(timesteps,dim),return_sequences=True))\n",
    "model.add(LSTM(50,input_shape=(timesteps,dim),return_sequences=True))\n",
    "model.add(LSTM(50,input_shape=(timesteps,dim),return_sequences=True))\n",
    "model.add(LSTM(50,input_shape=(timesteps,dim),return_sequences=True))\n",
    "model.add(LSTM(50,input_shape=(timesteps,dim),return_sequences=True))\n",
    "model.add(LSTM(50,input_shape=(timesteps,dim),return_sequences=True))\n",
    "model.add(LSTM(50,input_shape=(timesteps,dim),return_sequences=True))\n",
    "model.add(LSTM(50,input_shape=(timesteps,dim),return_sequences=True))\n",
    "model.add(LSTM(50,input_shape=(timesteps,dim),return_sequences=True))\n",
    "model.add(Dense(3))\n",
    "model.compile(loss='mae', optimizer='adam')\n",
    "\n",
    "def train(data):\n",
    "    data.shape = (300, 10, 3)\n",
    "    model.fit(data, data, epochs=50, batch_size=72, validation_data=(data, data), verbose=0, shuffle=False,callbacks=[LossHistory()])\n",
    "    data.shape = (3000, 3)\n",
    "\n",
    "def score(data):\n",
    "    data.shape = (300, 10, 3)\n",
    "    yhat =  model.predict(data)\n",
    "    yhat.shape = (3000, 3)\n",
    "    return yhat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a0062d-278e-414d-a838-e0783dc0e269",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------\n",
      "0.38889142870903015\n",
      "0.42711207270622253\n",
      "0.444160521030426\n",
      "0.4445486068725586\n",
      "0.44750458002090454\n",
      "0.347119003534317\n",
      "0.3821924924850464\n",
      "0.39599481225013733\n",
      "0.3923739790916443\n",
      "0.39436835050582886\n",
      "0.2589453458786011\n",
      "0.2920001447200775\n",
      "0.30200913548469543\n",
      "0.2988244295120239\n",
      "0.30028802156448364\n",
      "0.2626585364341736\n",
      "0.2849235534667969\n",
      "0.29126226902008057\n",
      "0.290312260389328\n",
      "0.2908632159233093\n",
      "0.224995955824852\n",
      "0.24460551142692566\n",
      "0.2526387870311737\n",
      "0.253427654504776\n",
      "0.2551236152648926\n",
      "0.20142149925231934\n",
      "0.22818347811698914\n",
      "0.23976394534111023\n",
      "0.2416950911283493\n",
      "0.24323312938213348\n",
      "0.20171914994716644\n",
      "0.222492054104805\n",
      "0.23051127791404724\n",
      "0.23217719793319702\n",
      "0.23300279676914215\n",
      "0.20880062878131866\n",
      "0.22260898351669312\n",
      "0.2272585779428482\n",
      "0.22873860597610474\n",
      "0.22916366159915924\n",
      "0.20833897590637207\n",
      "0.2194531112909317\n",
      "0.22285868227481842\n",
      "0.223546102643013\n",
      "0.22400808334350586\n",
      "0.19624044001102448\n",
      "0.20971210300922394\n",
      "0.21469222009181976\n",
      "0.21557730436325073\n",
      "0.2163671851158142\n",
      "0.1860225647687912\n",
      "0.20201802253723145\n",
      "0.20818710327148438\n",
      "0.20943240821361542\n",
      "0.2102711796760559\n",
      "0.18240156769752502\n",
      "0.197839617729187\n",
      "0.2034495621919632\n",
      "0.2047799527645111\n",
      "0.20543430745601654\n",
      "0.1827380657196045\n",
      "0.19595041871070862\n",
      "0.2003486305475235\n",
      "0.20150679349899292\n",
      "0.2019718885421753\n",
      "0.18212178349494934\n",
      "0.19360454380512238\n",
      "0.19731177389621735\n",
      "0.1982041299343109\n",
      "0.19858185946941376\n",
      "0.1796979010105133\n",
      "0.19039034843444824\n",
      "0.19396571815013885\n",
      "0.19472727179527283\n",
      "0.19506636261940002\n",
      "0.178189218044281\n",
      "0.18795804679393768\n",
      "0.19110195338726044\n",
      "0.19182807207107544\n",
      "0.19204288721084595\n",
      "0.1789674311876297\n",
      "0.18703144788742065\n",
      "0.18926836550235748\n",
      "0.18989136815071106\n",
      "0.18994922935962677\n",
      "0.17978709936141968\n",
      "0.18638892471790314\n",
      "0.18793433904647827\n",
      "0.18843156099319458\n",
      "0.1884167343378067\n",
      "0.17900462448596954\n",
      "0.18510618805885315\n",
      "0.18647070229053497\n",
      "0.18692103028297424\n",
      "0.18690964579582214\n",
      "0.17796652019023895\n",
      "0.18396854400634766\n",
      "0.1852135956287384\n",
      "0.18571189045906067\n",
      "0.18566255271434784\n",
      "0.17791955173015594\n",
      "0.18354156613349915\n",
      "0.18448135256767273\n",
      "0.18495596945285797\n",
      "0.1848587989807129\n",
      "0.17768216133117676\n",
      "0.1829988807439804\n",
      "0.18377922475337982\n",
      "0.18421128392219543\n",
      "0.18410614132881165\n",
      "0.17671024799346924\n",
      "0.1820467859506607\n",
      "0.18287475407123566\n",
      "0.18330776691436768\n",
      "0.1832112818956375\n",
      "0.17596253752708435\n",
      "0.18125349283218384\n",
      "0.18204106390476227\n",
      "0.18250054121017456\n",
      "0.18237541615962982\n"
     ]
    }
   ],
   "source": [
    "for i in range(1):\n",
    "\n",
    "    print(\"----------------\")\n",
    "    train(data_healthy_scaled)\n",
    "    yhat_healthy = score(data_healthy_scaled)\n",
    "    yhat_broken = score(data_broken_scaled)\n",
    "    data_healthy_scaled.shape = (3000, 3)\n",
    "    data_broken_scaled.shape = (3000, 3)\n",
    "\n",
    "print(\"----------------broken\")\n",
    "train(data_broken_scaled)\n",
    "yhat_healthy = score(data_healthy_scaled)\n",
    "yhat_broken = score(data_broken_scaled)\n",
    "data_healthy_scaled.shape = (3000, 3)\n",
    "data_broken_scaled.shape = (3000, 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18557f4-1a11-4ad4-b8c5-00f4497f13ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 470.538548,
   "end_time": "2021-03-22T20:37:13.369954",
   "environment_variables": {},
   "exception": null,
   "input_path": "/home/jovyan/work/examples/pipelines/pairs/component-library/transform/spark-csv-to-parquet.ipynb",
   "output_path": "/home/jovyan/work/examples/pipelines/pairs/component-library/transform/spark-csv-to-parquet.ipynb",
   "parameters": {},
   "start_time": "2021-03-22T20:29:22.831406",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
